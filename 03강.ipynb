{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cbow_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul # common folder의 layers.py 파일에서 MatMul class\n",
    "\n",
    "\n",
    "# 샘플 맥락 데이터\n",
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]]) # you에 대응하는 희소벡터 ([[]] : 1*7 행렬로 이해하겠다는 의미.)\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]]) # goodbye에 대응하는 희소벡터\n",
    "\n",
    "# 가중치 초기화\n",
    "W_in = np.random.randn(7, 3) # 7*3 행렬을 만들겠다.\n",
    "W_out = np.random.randn(3, 7) # 3*7 행렬을 만들겠다.\n",
    "\n",
    "# 계층 생성\n",
    "in_layer0 = MatMul(W_in) # MatMul층은 Affine층 중 특별한 것, 매개변수로 bias는 없고 weight만 있음.\n",
    "in_layer1 = MatMul(W_in) # 입력 MatMul층 2개, Weight mat 동일...\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "# 순전파\n",
    "h0 = in_layer0.forward(c0) # c0 통과시키면 h0\n",
    "h1 = in_layer1.forward(c1) # c1 통과시키면 h1\n",
    "h = 0.5 * (h0 + h1) # 두개 평균\n",
    "s = out_layer.forward(h) # activation func는 없음.\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MatMul\n",
    "/common/layers.py/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.np import *  # import numpy as np\n",
    "from common.config import GPU\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "\n",
    "\n",
    "class MatMul:\n",
    "    def __init__(self, W): # MatMul층은 Affine층 중 특별한 것, 매개변수로 bias는 없고 weight만 있음.\n",
    "        self.params = [W] # Weight: []안에 들어가 있음. 다른 층들이랑 일관성 유지하기 위해.\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x): # 순전파\n",
    "        W, = self.params # 위 초기화 함수에서의 인자 W. *** list,를 하면 []안에 있는 요소만 나옴.\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout): # 역전파\n",
    "        W, = self.params\n",
    "        dx = np.dot(dout, W.T) # dout에 Weight mat Transpose해서 곱해줘라.\n",
    "        dW = np.dot(self.x.T, dout) # x를 Transpose해서 곱해줘라.\n",
    "        self.grads[0][...] = dW # []안에 있는 걸 dW로 바꿔라. ***[...]: deep copy 깊은 복사, shape 유지\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple_cbow\n",
    "* 일반적인 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "\n",
    "\n",
    "class SimpleCBOW:\n",
    "    def __init__(self, vocab_size, hidden_size): # vocab_size 어휘개수: 입력층 뉴런 개수, # 은닉층 뉴런 개수: 단어를 벡터로 표현할 때 벡터 차원\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f') # 표준편차 0.01, 'f': 32bit라는 소리\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss() # cbow_predict.py에는 없던 softmax & cross_entropy 층\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer] # matmul의 인스턴스 3개, self_in_layer끼리는 동일 (weight이므로)\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target): # 문맥, # 타겟(예측시 정답)\n",
    "        h0 = self.in_layer0.forward(contexts[:, 0])\n",
    "        h1 = self.in_layer1.forward(contexts[:, 1])\n",
    "        h = (h0 + h1) * 0.5\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score, target)\n",
    "        return loss # 손실함수 값 리턴 46:00...\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer1.backward(da)\n",
    "        self.in_layer0.backward(da)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam\n",
    "from simple_cbow import SimpleCBOW\n",
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "model = SimpleCBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()\n",
    "\n",
    "word_vecs = model.word_vecs # input mat\n",
    "for word_id, word in id_to_word.items():\n",
    "    print(word, word_vecs[word_id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skip_gram.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_in : input weight\n",
    "# h: hidden\n",
    "# s: output\n",
    "# cbow: label = target (양 옆의 단어로 중앙의 단어 예측)\n",
    "# skip: label = context (중앙의 단어로 양 옆 단어 예측)\n",
    "\n",
    "# grads update...\n",
    "\n",
    "import simple_skip_gram import SimpleSkipGram"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a189447917acffb1567c89b7cb00fa9d2475a0f68c2a9e06a8cc7f2367540eba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
